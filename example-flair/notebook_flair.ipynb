{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6134e7be",
   "metadata": {},
   "source": [
    "# Distributed Training with LightningLite, SageMaker, and Flair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f1264",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "- [Getting Started with Tensor Parallelism using the SageMaker Model Parallelism Library\n",
    "](https://github.com/aws/amazon-sagemaker-examples/blob/main/training/distributed_training/pytorch/model_parallel/gpt-j/11_train_gptj_smp_tensor_parallel_notebook.ipynb)\n",
    "- [LightningLite Integration with Flair](https://github.com/flairNLP/flair/pull/2700)\n",
    "- [LIGHTNINGLITE - STEPPING STONE TO LIGHTNING](https://pytorch-lightning.readthedocs.io/en/stable/starter/lightning_lite.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b007dc3",
   "metadata": {},
   "source": [
    "## Launch training locally\n",
    "- [PYTORCH_LIGHTNING.LITE.LIGHTNINGLITE](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.lite.LightningLite.html#pytorch_lightning.lite.LightningLite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc44b236",
   "metadata": {},
   "source": [
    "###Â Original (single-instance single-gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e70eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python code/original/run_ner.py \\\n",
    "#     --dataset_name NER_ENGLISH_PERSON \\\n",
    "#     --model_name_or_path xlm-roberta-base \\\n",
    "#     --batch_size 32 \\\n",
    "#     --learning_rate 5e-05 \\\n",
    "#     --num_epochs 50 \\\n",
    "#     --context_size 64 \\\n",
    "#     --output_dir ner-english-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193cd093",
   "metadata": {},
   "source": [
    "### Custom training (single-instance multi-gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9724bab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-24 17:01:10,436 Reading data from /home/ec2-user/.flair/datasets/ner_english_person\n",
      "2022-05-24 17:01:10,436 Train: /home/ec2-user/.flair/datasets/ner_english_person/bigFile.conll\n",
      "2022-05-24 17:01:10,436 Dev: None\n",
      "2022-05-24 17:01:10,436 Test: None\n",
      "2022-05-24 17:01:15,657 Corpus: 28362 train + 3151 dev + 3501 test sentences\n",
      "2022-05-24 17:01:15,657 Computing label dictionary. Progress:\n",
      "28362it [00:00, 74961.01it/s]\n",
      "2022-05-24 17:01:16,036 Dictionary created for label 'ner' with 4 values: M (seen 28093 times), F (seen 4520 times), A (seen 597 times)\n",
      "2022-05-24 17:01:16,036 Dictionary with 4 tags: <unk>, M, F, A\n",
      "2022-05-24 17:01:27,136 SequenceTagger predicts: Dictionary with 4 tags: <unk>, M, F, A\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "2022-05-24 17:01:29,067 Reading data from /home/ec2-user/.flair/datasets/ner_english_person\n",
      "2022-05-24 17:01:29,067 Train: /home/ec2-user/.flair/datasets/ner_english_person/bigFile.conll\n",
      "2022-05-24 17:01:29,067 Dev: None\n",
      "2022-05-24 17:01:29,067 Test: None\n",
      "2022-05-24 17:01:31,934 Reading data from /home/ec2-user/.flair/datasets/ner_english_person\n",
      "2022-05-24 17:01:31,934 Train: /home/ec2-user/.flair/datasets/ner_english_person/bigFile.conll\n",
      "2022-05-24 17:01:31,935 Dev: None\n",
      "2022-05-24 17:01:31,935 Test: None\n",
      "2022-05-24 17:01:34,360 Corpus: 28362 train + 3151 dev + 3501 test sentences\n",
      "2022-05-24 17:01:34,360 Computing label dictionary. Progress:\n",
      "28362it [00:00, 73778.15it/s]\n",
      "2022-05-24 17:01:34,746 Dictionary created for label 'ner' with 4 values: M (seen 28093 times), F (seen 4520 times), A (seen 597 times)\n",
      "2022-05-24 17:01:34,746 Dictionary with 4 tags: <unk>, M, F, A\n",
      "2022-05-24 17:01:36,611 Reading data from /home/ec2-user/.flair/datasets/ner_english_person\n",
      "2022-05-24 17:01:36,611 Train: /home/ec2-user/.flair/datasets/ner_english_person/bigFile.conll\n",
      "2022-05-24 17:01:36,611 Dev: None\n",
      "2022-05-24 17:01:36,611 Test: None\n",
      "2022-05-24 17:01:36,645 Corpus: 24313 train + 2701 dev + 3002 test sentences\n",
      "2022-05-24 17:01:36,645 Computing label dictionary. Progress:\n",
      "24313it [00:00, 71474.11it/s]\n",
      "2022-05-24 17:01:36,986 Dictionary created for label 'ner' with 4 values: M (seen 23009 times), F (seen 3704 times), A (seen 357 times)\n",
      "2022-05-24 17:01:36,986 Dictionary with 4 tags: <unk>, M, F, A\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "2022-05-24 17:01:41,815 Corpus: 28362 train + 3151 dev + 3501 test sentences\n",
      "2022-05-24 17:01:41,815 Computing label dictionary. Progress:\n",
      "28362it [00:00, 69954.56it/s]\n",
      "2022-05-24 17:01:42,222 Dictionary created for label 'ner' with 4 values: M (seen 28093 times), F (seen 4520 times), A (seen 597 times)\n",
      "2022-05-24 17:01:42,222 Dictionary with 4 tags: <unk>, M, F, A\n",
      "2022-05-24 17:01:46,382 SequenceTagger predicts: Dictionary with 4 tags: <unk>, M, F, A\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "2022-05-24 17:01:48,298 SequenceTagger predicts: Dictionary with 4 tags: <unk>, M, F, A\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "2022-05-24 17:01:53,555 SequenceTagger predicts: Dictionary with 4 tags: <unk>, M, F, A\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "2022-05-24 17:01:57,333 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,333 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,333 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,333 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,334 Model: \"_LiteModule(\n",
      "  (_module): DistributedDataParallel(\n",
      "    (module): SequenceTagger(\n",
      "      (embeddings): TransformerWordEmbeddings(\n",
      "        (model): XLMRobertaModel(\n",
      "          (embeddings): RobertaEmbeddings(\n",
      "            (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
      "            (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "            (token_type_embeddings): Embedding(1, 768)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (encoder): RobertaEncoder(\n",
      "            (layer): ModuleList(\n",
      "              (0): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (1): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (2): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (3): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (4): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (5): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (6): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (7): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (8): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (9): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (10): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (11): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (pooler): RobertaPooler(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (activation): Tanh()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (word_dropout): WordDropout(p=0.05)\n",
      "      (locked_dropout): LockedDropout(p=0.5)\n",
      "      (linear): Linear(in_features=768, out_features=4, bias=True)\n",
      "      (loss_function): CrossEntropyLoss()\n",
      "    )\n",
      "  )\n",
      ")\"\n",
      "2022-05-24 17:01:57,334 Model: \"_LiteModule(\n",
      "  (_module): DistributedDataParallel(\n",
      "    (module): SequenceTagger(\n",
      "      (embeddings): TransformerWordEmbeddings(\n",
      "        (model): XLMRobertaModel(\n",
      "          (embeddings): RobertaEmbeddings(\n",
      "            (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
      "            (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "            (token_type_embeddings): Embedding(1, 768)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (encoder): RobertaEncoder(\n",
      "            (layer): ModuleList(\n",
      "              (0): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (1): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (2): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (3): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (4): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (5): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (6): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (7): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (8): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (9): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (10): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (11): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (pooler): RobertaPooler(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (activation): Tanh()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (word_dropout): WordDropout(p=0.05)\n",
      "      (locked_dropout): LockedDropout(p=0.5)\n",
      "      (linear): Linear(in_features=768, out_features=4, bias=True)\n",
      "      (loss_function): CrossEntropyLoss()\n",
      "    )\n",
      "  )\n",
      ")\"\n",
      "2022-05-24 17:01:57,334 Model: \"_LiteModule(\n",
      "  (_module): DistributedDataParallel(\n",
      "    (module): SequenceTagger(\n",
      "      (embeddings): TransformerWordEmbeddings(\n",
      "        (model): XLMRobertaModel(\n",
      "          (embeddings): RobertaEmbeddings(\n",
      "            (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
      "            (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "            (token_type_embeddings): Embedding(1, 768)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (encoder): RobertaEncoder(\n",
      "            (layer): ModuleList(\n",
      "              (0): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (1): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (2): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (3): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (4): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (5): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (6): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (7): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (8): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (9): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (10): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (11): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (pooler): RobertaPooler(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (activation): Tanh()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (word_dropout): WordDropout(p=0.05)\n",
      "      (locked_dropout): LockedDropout(p=0.5)\n",
      "      (linear): Linear(in_features=768, out_features=4, bias=True)\n",
      "      (loss_function): CrossEntropyLoss()\n",
      "    )\n",
      "  )\n",
      ")\"\n",
      "2022-05-24 17:01:57,334 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,335 Model: \"_LiteModule(\n",
      "  (_module): DistributedDataParallel(\n",
      "    (module): SequenceTagger(\n",
      "      (embeddings): TransformerWordEmbeddings(\n",
      "        (model): XLMRobertaModel(\n",
      "          (embeddings): RobertaEmbeddings(\n",
      "            (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
      "            (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "            (token_type_embeddings): Embedding(1, 768)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (encoder): RobertaEncoder(\n",
      "            (layer): ModuleList(\n",
      "              (0): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (1): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (2): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (3): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (4): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (5): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (6): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (7): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (8): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (9): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (10): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (11): RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (pooler): RobertaPooler(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (activation): Tanh()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (word_dropout): WordDropout(p=0.05)\n",
      "      (locked_dropout): LockedDropout(p=0.5)\n",
      "      (linear): Linear(in_features=768, out_features=4, bias=True)\n",
      "      (loss_function): CrossEntropyLoss()\n",
      "    )\n",
      "  )\n",
      ")\"\n",
      "2022-05-24 17:01:57,338 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,336 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,339 Corpus: \"Corpus: 28362 train + 3151 dev + 3501 test sentences\"\n",
      "2022-05-24 17:01:57,339 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,339 Parameters:\n",
      "2022-05-24 17:01:57,339  - learning_rate: \"0.000050\"\n",
      "2022-05-24 17:01:57,339  - mini_batch_size: \"32\"\n",
      "2022-05-24 17:01:57,339 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,339  - patience: \"3\"\n",
      "2022-05-24 17:01:57,339  - anneal_factor: \"0.5\"\n",
      "2022-05-24 17:01:57,339  - max_epochs: \"2\"\n",
      "2022-05-24 17:01:57,339  - shuffle: \"True\"\n",
      "2022-05-24 17:01:57,339  - train_with_dev: \"False\"\n",
      "2022-05-24 17:01:57,339  - batch_growth_annealing: \"False\"\n",
      "2022-05-24 17:01:57,339 Corpus: \"Corpus: 28362 train + 3151 dev + 3501 test sentences\"\n",
      "2022-05-24 17:01:57,339 Corpus: \"Corpus: 24313 train + 2701 dev + 3002 test sentences\"\n",
      "2022-05-24 17:01:57,339 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,339 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,339 Model training base path: \"ner-english-test\"\n",
      "2022-05-24 17:01:57,339 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,339 Parameters:\n",
      "2022-05-24 17:01:57,339 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,339 Parameters:\n",
      "2022-05-24 17:01:57,339  - learning_rate: \"0.000050\"\n",
      "2022-05-24 17:01:57,339  - learning_rate: \"0.000050\"\n",
      "2022-05-24 17:01:57,339 Device: cuda:3\n",
      "2022-05-24 17:01:57,339  - mini_batch_size: \"32\"\n",
      "2022-05-24 17:01:57,339  - mini_batch_size: \"32\"\n",
      "2022-05-24 17:01:57,339 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,339  - patience: \"3\"\n",
      "2022-05-24 17:01:57,339  - patience: \"3\"\n",
      "2022-05-24 17:01:57,339 Embeddings storage mode: gpu\n",
      "2022-05-24 17:01:57,339  - anneal_factor: \"0.5\"\n",
      "2022-05-24 17:01:57,339 Corpus: \"Corpus: 28362 train + 3151 dev + 3501 test sentences\"\n",
      "2022-05-24 17:01:57,339  - anneal_factor: \"0.5\"\n",
      "2022-05-24 17:01:57,339 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,339  - max_epochs: \"2\"\n",
      "2022-05-24 17:01:57,339 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,339  - max_epochs: \"2\"\n",
      "2022-05-24 17:01:57,339  - shuffle: \"True\"\n",
      "2022-05-24 17:01:57,339 Parameters:\n",
      "2022-05-24 17:01:57,339  - shuffle: \"True\"\n",
      "2022-05-24 17:01:57,339  - train_with_dev: \"False\"\n",
      "2022-05-24 17:01:57,339  - learning_rate: \"0.000050\"\n",
      "2022-05-24 17:01:57,339  - train_with_dev: \"False\"\n",
      "2022-05-24 17:01:57,339  - batch_growth_annealing: \"False\"\n",
      "2022-05-24 17:01:57,339  - mini_batch_size: \"32\"\n",
      "2022-05-24 17:01:57,339  - batch_growth_annealing: \"False\"\n",
      "2022-05-24 17:01:57,339 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,339  - patience: \"3\"\n",
      "2022-05-24 17:01:57,339 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,339 Model training base path: \"ner-english-test\"\n",
      "2022-05-24 17:01:57,340  - anneal_factor: \"0.5\"\n",
      "2022-05-24 17:01:57,340 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,340 Model training base path: \"ner-english-test\"\n",
      "2022-05-24 17:01:57,340  - max_epochs: \"2\"\n",
      "2022-05-24 17:01:57,340 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,340 Device: cuda:1\n",
      "2022-05-24 17:01:57,340  - shuffle: \"True\"\n",
      "2022-05-24 17:01:57,340 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,340 Device: cuda:2\n",
      "2022-05-24 17:01:57,340  - train_with_dev: \"False\"\n",
      "2022-05-24 17:01:57,340 Embeddings storage mode: gpu\n",
      "2022-05-24 17:01:57,340 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,340  - batch_growth_annealing: \"False\"\n",
      "2022-05-24 17:01:57,340 Embeddings storage mode: gpu\n",
      "2022-05-24 17:01:57,340 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,340 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,340 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,340 Model training base path: \"ner-english-test\"\n",
      "2022-05-24 17:01:57,340 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,340 Device: cuda:0\n",
      "2022-05-24 17:01:57,340 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:01:57,340 Embeddings storage mode: gpu\n",
      "2022-05-24 17:01:57,340 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-24 17:02:30,867 epoch 1 - iter 19/190 - loss 1.82335719 - samples/sec: 18.14 - lr: 0.000050\n",
      "2022-05-24 17:02:35,713 epoch 1 - iter 22/222 - loss 1.81051176 - samples/sec: 18.35 - lr: 0.000050\n",
      "2022-05-24 17:02:35,773 epoch 1 - iter 22/222 - loss 1.78473256 - samples/sec: 18.32 - lr: 0.000050\n",
      "2022-05-24 17:02:36,028 epoch 1 - iter 22/222 - loss 1.78120953 - samples/sec: 18.20 - lr: 0.000050\n",
      "2022-05-24 17:03:04,607 epoch 1 - iter 38/190 - loss 1.80936527 - samples/sec: 18.02 - lr: 0.000050\n",
      "2022-05-24 17:03:14,843 epoch 1 - iter 44/222 - loss 1.84050313 - samples/sec: 18.00 - lr: 0.000050\n",
      "2022-05-24 17:03:15,107 epoch 1 - iter 44/222 - loss 1.83463176 - samples/sec: 17.90 - lr: 0.000050\n",
      "2022-05-24 17:03:15,314 epoch 1 - iter 44/222 - loss 1.77008273 - samples/sec: 17.93 - lr: 0.000050\n",
      "2022-05-24 17:03:38,451 epoch 1 - iter 57/190 - loss 1.79675091 - samples/sec: 17.97 - lr: 0.000050\n",
      "2022-05-24 17:03:55,388 epoch 1 - iter 66/222 - loss 1.83902564 - samples/sec: 17.37 - lr: 0.000050\n",
      "2022-05-24 17:03:55,717 epoch 1 - iter 66/222 - loss 1.84378592 - samples/sec: 17.34 - lr: 0.000050\n",
      "2022-05-24 17:03:56,112 epoch 1 - iter 66/222 - loss 1.78886332 - samples/sec: 17.26 - lr: 0.000050\n"
     ]
    }
   ],
   "source": [
    "!python custom_run_ner.py \\\n",
    "    --dataset_name NER_ENGLISH_PERSON \\\n",
    "    --model_name_or_path xlm-roberta-base \\\n",
    "    --batch_size 32 \\\n",
    "    --learning_rate 5e-05 \\\n",
    "    --embeddings_storage_mode gpu \\\n",
    "    --num_epochs 2 \\\n",
    "    --context_size 64 \\\n",
    "    --accelerator gpu \\\n",
    "    --strategy ddp \\\n",
    "    --devices 4 \\\n",
    "    --num_nodes 1 \\\n",
    "    --precision 16 \\\n",
    "    --output_dir ner-english-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c374613b",
   "metadata": {},
   "source": [
    "## Launch training remotely using SageMaker Training Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf78974",
   "metadata": {},
   "source": [
    "### Permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb77b4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::110564771975:role/service-role/AmazonSageMaker-ExecutionRole-20210806T162946\n",
      "sagemaker bucket: sagemaker-eu-west-2-110564771975\n",
      "sagemaker session region: eu-west-2\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf52188",
   "metadata": {},
   "source": [
    "### Creating an Estimator and start a training job with `custom_run_ner.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5cbaa7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e78eeec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={\n",
    "    'dataset_name': 'NER_ENGLISH_PERSON',\n",
    "    'model_name_or_path': \"xlm-roberta-base\",\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 5e-05,\n",
    "    'embeddings_storage_mode': 'gpu',\n",
    "    'accelerator': 'gpu',\n",
    "    'strategy': 'ddp',\n",
    "#     'devices': 4,\n",
    "    'num_nodes': 1,\n",
    "    'precision': 16,\n",
    "    'num_epochs': 2,\n",
    "    'context_size': 64,\n",
    "    'output_dir': '/opt/ml/model',\n",
    "}\n",
    "\n",
    "# configuration for running training on smdistributed Data Parallel\n",
    "# distribution = {'smdistributed':{'dataparallel':{ 'enabled': True }}}\n",
    "\n",
    "# instance configurations\n",
    "instance_type='ml.p3.8xlarge'\n",
    "# instance_type='ml.g4dn.12xlarge'\n",
    "instance_count=1\n",
    "volume_size=100\n",
    "\n",
    "# metric definition to extract the results\n",
    "metric_definitions=[\n",
    "    {'Name': 'epoch', 'Regex': \"epoch.*=\\D*(.*?)$\"},\n",
    "    {'Name': 'loss', 'Regex': \"loss.*=\\D*(.*?)$\"},\n",
    "    {'Name': 'f1', 'Regex': \"f1.*=\\D*(.*?)$\"},\n",
    "    {'Name': 'precision', 'Regex': \"precision.*=\\D*(.*?)$\"},\n",
    "    {'Name': 'recall', 'Regex': \"recall.*=\\D*(.*?)$\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c17a7508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator\n",
    "huggingface_estimator = HuggingFace(entry_point='custom_run_ner.py',\n",
    "                                    source_dir='.',\n",
    "                                    metric_definitions=metric_definitions,\n",
    "                                    instance_type=instance_type,\n",
    "                                    instance_count=instance_count,\n",
    "                                    volume_size=volume_size,\n",
    "                                    role=role,\n",
    "                                    transformers_version='4.17.0',\n",
    "                                    pytorch_version='1.10.2',\n",
    "                                    py_version='py38',\n",
    "#                                     distribution= distribution,\n",
    "                                    hyperparameters = hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "429989ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting the train job\n",
    "huggingface_estimator.fit(wait=False)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAA60AAABpCAYAAADRNMXgAAAK2WlDQ1BJQ0MgUHJvZmlsZQAASImVlwdUk8kWgOf///RCgAACUkJvgnQCSAk9FOlVVEISSCghJgQEu7K4gquCiAioK7gqouBaAFkLYsGKYsO+QRYVdV0s2FDZH3iE3X3nvXfePWfOfLm5c++dOXP/cwcAqjdHLM6ClQHIFuVKogJ9GAmJSQz8E4AFmoAAIEDmcKViVkREKEBlcv67vL+N2qFyw3rM17///19FlceXcgGAklFO5Um52Sh3oOM3rliSCwCyE9Ub5eeKx/g8ymoSNEGUH4xx+gQPjXHqOGMw4zYxUb4oawJAoHA4knQAKMaonpHHTUf9UPxQthXxhCKU0d/Akyvg8FA+jPKM7OycMZajbI7aiwGgElBmpv7FZ/rf/Kcq/HM46Qqe2Ne4EPyEUnEWp+D/PJr/LdlZsskYpuigCCRBUWMzen53MnNCFCxKnR0+yULeuP04C2RBsZPMlfomTTKP4xeiWJs1O3SS04QBbIWfXHbMJPOl/tGTLMmJUsRKk/iyJpkjmYory4xV6AV8tsJ/oSAmfpLzhHGzJ1maGR0yZeOr0EtkUYr8+aJAn6m4AYq9Z0v/sl8hW7E2VxATpNg7Zyp/vog15VOaoMiNx/fzn7KJVdiLc30UscRZEQp7flagQi/Ni1aszUUv59TaCMUZZnCCIyYZhIJAwACRIAj45fIXjt1R4JsjLpAI0wW5DBZaZXwGW8S1mcGwt7W3B2CsZieuwduo8VqENE5M6XLQGmK+R+ukbEqXWgFAazEAmvemdMbbAKAVAdDSyZVJ8iZ0Y+WEfgtIgAbUgBbQA0bAHFgDe+AM3IE38AfBIBzEgEQwD3CBAGQDCcgHi8EKUAxKwQawCVSD7aAe7AH7wUHQCo6BU+AcuASugVvgPpCDAfACDIH3YASCIDxEheiQFqQPmUBWkD3EhDwhfygUioISoRQoHRJBMmgxtAoqhcqhamgH1AD9DB2FTkEXoB7oLtQHDUJvoM8wAlNgNVgXNoVnwkyYBYfAMfBcOB1eABfCRfA6uAqug/fBLfAp+BJ8C5bDL+BhBCBkRAMxQKwRJuKLhCNJSBoiQZYiJUglUoc0Ie1IF3IDkSMvkU8YHIaOYWCsMe6YIEwshotZgFmKWYupxuzBtGDOYG5g+jBDmG9YKlYHa4V1w7KxCdh0bD62GFuJ3YU9gj2LvYUdwL7H4XAaODOcCy4Il4jLwC3CrcVtxTXjOnA9uH7cMB6P18Jb4T3w4XgOPhdfjN+C34c/ib+OH8B/JJAJ+gR7QgAhiSAirCRUEvYSThCuE54SRojKRBOiGzGcyCMWENcTdxLbiVeJA8QRkgrJjORBiiFlkFaQqkhNpLOkB6S3ZDLZkOxKjiQLycvJVeQD5PPkPvIniirFkuJLSabIKOsouykdlLuUt1Qq1ZTqTU2i5lLXURuop6mPqB+V6Eo2SmwlntIypRqlFqXrSq9oRJoJjUWbRyukVdIO0a7SXioTlU2VfZU5ykuVa5SPKvcqD6vQVexUwlWyVdaq7FW5oPJMFa9qquqvylMtUq1XPa3aT0foRnRfOpe+ir6TfpY+oIZTM1Njq2WolartV+tWG1JXVXdUj1NfqF6jflxdroFomGqwNbI01msc1Lit8Xma7jTWNP60NdOapl2f9kFzuqa3Jl+zRLNZ85bmZy2Glr9WplaZVqvWQ22MtqV2pHa+9jbts9ovp6tNd5/OnV4y/eD0ezqwjqVOlM4inXqdyzrDunq6gbpi3S26p3Vf6mnoeetl6FXondAb1Kfre+oL9Sv0T+o/Z6gzWIwsRhXjDGPIQMcgyEBmsMOg22DE0Mww1nClYbPhQyOSEdMozajCqNNoyFjfOMx4sXGj8T0TognTRGCy2aTL5IOpmWm86WrTVtNnZppmbLNCs0azB+ZUcy/zBeZ15jctcBZMi0yLrRbXLGFLJ0uBZY3lVSvYytlKaLXVqmcGdobrDNGMuhm91hRrlnWedaN1n42GTajNSptWm1czjWcmzSyb2TXzm62TbZbtTtv7dqp2wXYr7drt3thb2nPta+xvOlAdAhyWObQ5vHa0cuQ7bnO840R3CnNa7dTp9NXZxVni3OQ86GLskuJS69LLVGNGMNcyz7tiXX1cl7kec/3k5uyW63bQ7Q93a/dM973uz2aZzeLP2jmr38PQg+Oxw0PuyfBM8fzRU+5l4MXxqvN67G3kzfPe5f2UZcHKYO1jvfKx9ZH4HPH54Ovmu8S3ww/xC/Qr8ev2V/WP9a/2fxRgGJAe0BgwFOgUuCiwIwgbFBJUFtTL1mVz2Q3soWCX4CXBZ0IoIdEh1SGPQy1DJaHtYXBYcNjGsAezTWaLZreGg3B2+MbwhxFmEQsifonERUZE1kQ+ibKLWhzVFU2Pnh+9N/p9jE/M+pj7seaxstjOOFpcclxD3Id4v/jyeHnCzIQlCZcStROFiW1J+KS4pF1Jw3P852yaM5DslFycfHuu2dyFcy/M056XNe/4fNp8zvxDKdiU+JS9KV844Zw6znAqO7U2dYjry93MfcHz5lXwBvke/HL+0zSPtPK0Z+ke6RvTBwVegkrBS6GvsFr4OiMoY3vGh8zwzN2Zo1nxWc3ZhOyU7KMiVVGm6EyOXs7CnB6xlbhYLF/gtmDTgiFJiGSXFJLOlbblqqHN0WWZuew7WV+eZ15N3sf8uPxDC1UWihZeLrAsWFPwtDCg8KdFmEXcRZ2LDRavWNy3hLVkx1JoaerSzmVGy4qWDSwPXL5nBWlF5oorK21Xlq98typ+VXuRbtHyov7vAr9rLFYqlhT3rnZfvf17zPfC77vXOKzZsuZbCa/kYqltaWXpl7XctRd/sPuh6ofRdWnrutc7r9+2AbdBtOF2mVfZnnKV8sLy/o1hG1sqGBUlFe82zd90odKxcvtm0mbZZnlVaFXbFuMtG7Z8qRZU36rxqWmu1aldU/thK2/r9W3e25q2624v3f75R+GPd3YE7mipM62rrMfV59U/2Rm3s+sn5k8Nu7R3le76ulu0W74nas+ZBpeGhr06e9c3wo2yxsF9yfuu7ffb39Zk3bSjWaO59AA4IDvw/OeUn28fDDnYeYh5qOmwyeHaI/QjJS1QS0HLUKugVd6W2NZzNPhoZ7t7+5FfbH7ZfczgWM1x9ePrT5BOFJ0YPVl4crhD3PHyVPqp/s75nfdPJ5y+eSbyTPfZkLPnzwWcO93F6jp53uP8sQtuF45eZF5sveR8qeWy0+UjV5yuHOl27m656nK17ZrrtfaeWT0nrntdP3XD78a5m+ybl27NvtVzO/b2nd7kXvkd3p1nd7Puvr6Xd2/k/vIH2AclD5UfVj7SeVT3q8WvzXJn+fE+v77Lj6Mf3+/n9r/4Tfrbl4GiJ9QnlU/1nzY8s392bDBg8NrzOc8HXohfjLws/l3l99pX5q8O/+H9x+WhhKGB15LXo2/WvtV6u/ud47vO4YjhR++z3498KPmo9XHPJ+anrs/xn5+O5H/Bf6n6avG1/VvItwej2aOjYo6EM94KIOiA09IAeLMb7YkTAaBfA4A0Z6KnHhdo4h0wTuA/8UTfPS7OANT3AhCzCIDQKwBsqUbbWNQ/DX0LRNBQvTuAHRwU418iTXOwn/BF8UJbk4ejo2/NAcCXAfC1bHR0pH509Gs9mux9ADoKJnr5MdFD3xX5lgA5/Ps9u7Ll4B8y0ef/ZY//nMFYBo7gn/OfNi0Yxhy4wsUAAABWZVhJZk1NACoAAAAIAAGHaQAEAAAAAQAAABoAAAAAAAOShgAHAAAAEgAAAESgAgAEAAAAAQAAA62gAwAEAAAAAQAAAGkAAAAAQVNDSUkAAABTY3JlZW5zaG90gXAQIAAAAdZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IlhNUCBDb3JlIDYuMC4wIj4KICAgPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4KICAgICAgPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIKICAgICAgICAgICAgeG1sbnM6ZXhpZj0iaHR0cDovL25zLmFkb2JlLmNvbS9leGlmLzEuMC8iPgogICAgICAgICA8ZXhpZjpQaXhlbFlEaW1lbnNpb24+MTA1PC9leGlmOlBpeGVsWURpbWVuc2lvbj4KICAgICAgICAgPGV4aWY6UGl4ZWxYRGltZW5zaW9uPjk0MTwvZXhpZjpQaXhlbFhEaW1lbnNpb24+CiAgICAgICAgIDxleGlmOlVzZXJDb21tZW50PlNjcmVlbnNob3Q8L2V4aWY6VXNlckNvbW1lbnQ+CiAgICAgIDwvcmRmOkRlc2NyaXB0aW9uPgogICA8L3JkZjpSREY+CjwveDp4bXBtZXRhPgpq+ilsAABAAElEQVR4Ae2dB4AURdOGixwkS85JoqKASM6ioihByYKAIijyASrR9KOCIFFAEQmKCCjRhIIgIIjknPORczxy2r/e3utlbtm9vYM79g7egt2Z6ek0z8zOTXVV18S7cuWKSygkQAIkQAIkQAIkQAIkQAIkQAIkcJcJrNm4SfLmyimJEyXy23J8v3u4gwRIgARIgARIgARIgARIgARIgASCTIBKa5BPAJsnARIgARIgARIgARIgARIgARLwT4BKq3823EMCJEACJEACJEACJEACJEACJBBkAlRag3wC2DwJkAAJkAAJkAAJkAAJkAAJkIB/AlRa/bPhHhIgARIgARIgARIgARIgARIggSAToNIa5BPA5kmABEiABEiABEiABEiABEiABPwTSHg6NNT/Xu4hARIgARIgARIgARIgARIgARIggSASSJgmZcogNs+mSYAESIAESIAESIAESIAESIAESMA/AboH+2fDPSRAAiRAAiRAAiRAAiRAAiRAAkEmQKU1yCeAzZMACZAACZAACZAACZAACZAACfgnQKXVPxvuIQESIAESIAESIAESIAESIAESCDIBKq1BPgFsngRIgARIgARIgARIgARIgARIwD8BKq3+2XAPCZAACZAACZAACZAACZAACZBAkAlQaQ3yCWDzJEACJEACJEACJEACJEACJEAC/glQafXPhntIgARIgARIgARIgARIgARIgASCTIBKa5BPAJsnARIgARIgARIgARIgARIgARLwT4BKq3823EMCJEACJEACJEACJEACJEACJBBkAlRag3wC2DwJkAAJkAAJkAAJkAAJkAAJkIB/AlRa/bPhHhIgARIgARIgARIgARIgARIggSATuOeU1tOhoUFGyuZJgARIgARIIHIE+DcrcpyYiwScBPi7cdKIG+s8Z3HjPMXmXt5zSmtshs2+kQAJkAAJkAAJkAAJkAAJkAAJRI0Aldao8WJuEiABEiABEiABEiABEiABEiCBu0iASutdhM2mSIAESIAESIAESIAESIAESIAEokaASmvUeDE3CZAACZAACZAACZAACZAACZDAXSRApfUuwmZTJEACJEACJEACJEACJEACJEACUSNApTVqvJibBEiABEiABOIcgWvXrgelz7t3h8iAgV/Iho2b7mr7oefOydBhw2XmrNl3tV02RgLRTWDVmvUydvwkOXnqdHRXfU/V53K55OLFS/fUMfFgwhNIGH6TW/4IvNmpu1y7dk0eKVpY2rdt5cnWZ8BQ2RWyV7p2aif58ub2pHOFBEiABEiABIJJAArbyFFjZOPGzXLu/Hkp8FB+ebXVK9K0SaMY6dbBg4fk8JEjkjdPHkmTJrVpY/iIUTJh4k+yas1aGf/9mBhpN1Rfdbd9x05Jnz695MyR3bQxd+586dtvoFkP2blZEibk406MwL/HKh0yfLRs2LTFc1SpUqaUXDmzS70Xakq2rFk86TG1sitkj1G8ChXILwkSJDDNDPt6jFy6fFkSJUokTRrUjamm42y9O3eFyMzZ82Tl6nWGU9IkSSR3rhzyXteOkiB+fHPv27N3v6RLm0ayZM4UqePE/TKqZSJVMTPdEQHexSOJ7/TpMybn4qUrpGql8vJwkYJm+/iJU3Lu3Hm5cvVqJGtiNhIgARIggdhI4Ptp0+TYiZMRdi1HlizSoNZzEeaJDTt7ftJbFdZvTVdSPPCAlC9XVh+GL8qx4ydirHv9Bw6WSZOnyeiRw+Xpp5407bzctJEkTZpEajxZPcbanfXXHOn4dhdp/VpL+eiDHqad8uXLSpvWr0ru3LmosMYYeXfFTz3zvGzafFPR89Vc2TKlZfJPP/jaFavSTpx0P9NB8cmQ4UE5duyEHDx0WPDs95YaLMqVfjxG+9uz90C5qs+TXw3uI2lSpzJtNWvykmzasl0qlS8To23HxcqP6/36/3r3l+vXb0j6B9NJ3ry55Py5C3L46DERtbxCFi1ebizV5cs+Ie1eb2HSAn3dTplAdcal/bH1byGV1tu4ir4eNVa+6P+pGcHxLv7LjFny97yFcuZsqNy4cV3y5MoprZo3NqM+Z0PPSU/9cT2YLp0ULvSQzJozX87raE7hgg/JU9WryNSfZ8jBw0ckq44E4SZVpFABU/3efQdk1HfjZY8uE+locbkyj8srTRt4RuG8+8BtEiABEiCBqBO4fPlKwEKXrlwOmCfYGebPX+BRWKdP/VEeL1lC4sWLF65bHTp1lv3790vfPr2MG+1h/dvz08TvZeeu3dL7s89l5crVkvyB5FKvzgvSsUN7VfwSyLgfJsqPk6bIgf0H5NKlSwLFsGuXd4wFt3effvLHH7NMG720/DcjR0vP//tANm7arJbeTfpA+aBUrFDO7A9Ra9KnvT+XFStWmjYqVigv3bu+a6yzZ86ckVavtZVc+rezcqWK8t3YHwQuxtWqVZbu3TpLBrWmOmXK1OkyRN2AIdOn/yrr1q2Xhg3qS0G1VK1Zu1atJfuk2cuNZcmSZdJvwCDtczkdaD5n3IYvnL8gLVs2l+zZssqY78bJTrXW1qz5tOlLxowZTJ0R8TAZ+CVn9XknkOC8xiWBgvPqK41V73GpwjNZ/vp7vgwf+Z0ULVxArly5KvCyg/Tu2UOSJE4s3/0wSdbrdf70k1X1ea6yTPn5d6PoNm34onoZrJM16zbKB906yZLlq3w+I6ZWBfWbMeOMwop6P+rVTxKqpfXzTz+Qdes3yV79ze07cFCvVbe1d8WqtTJx8nQ5euy4pFRrcIUypaThS7XNc+GadRtk3MQpUrL4o6rMXZfFy1bKJXWbLVe2lLz2ShNUf8/Iho1bjMKKA+rds7tggM4peM6e+ssMk7RsxWrZpfeSJ6tWkhKPPSIj9bk6JGSfXNZ7epLESaR61QrSuH5d82zuq0xa9R6ZPP03yZE9m3Rs19rU+V7PPuZe2K5NS8mrA2TLV66RWXqtbN+xW+95aaVMqZJSv97zzi7FifXY+reQSmsULx878jbjz9nywnNP31IaCitGfpInSyYXLl6VHeq2MGnar9JF3Ydx8zh0+Kj5ON1PNmzaqu4oWz117dm3XyZOmi6ffNhVoOi+1/Mz86N013lR5mgbjxV72PzoPIW4QgIkQAIkcEcEnqlSWSb97n7AaVavrmRURQuy79AhT/ozlSvfURt3o/DS5StMM6UeLyn4+JL16zfItu07pEo1998xKJVQLJ6rVde40+XMmUP2qsI3eMiXUrZsaWOphcK6du06wb7jJ04ILJx42B7Yv698//14Uw5t7VLFF59z+vfroD5oL122QsvkNN1AG888W9uTV7Se8RN+NMrmjN+myVWdhoP8+MBqawXrxYo9Ii2av2yTzPLvufNNW9hAn/CpWLGCZMmS2dSB44KcPnPaU69JCPvq13+Qc1MmT5kmRQoXMlbbQDzCFbyPNwYN7Cv1G4Y/L944Bg383DspTmxjsKdx/TpGaYU1b9fuvZIxw4PmOQ4HAKUWEqK/FTzf4fkPcuTIMbPd/wv3gArS4JHn7xmxfr0XZK0qp1Zg4YWg/hB1bT2ilkPr8bduw2YZOHSEzWrSf585R0LV66/Nq83McyP68rs+pzpl7vx/pUqFspI/Xx5ncpxef+Thwp7+t+vUQ+o+X9MonylTpDDpUFThDQmBBRtc4G0Cpps2b1MlP74agxLp8/pF+e2P2WrNLiv+yuBaQPlr+ixvZbdOD4RcuHDJ1Dto2DdmO1WqlGZAYeF/S+Ok0hpb/xYyEJO5vCL/1bpFU5MZoy2nz5y9peC7Hd6Q0V8NlFFfDZA+H79n9mOEzd7YbAGMuI0f86X612c0SaVKPiZjv/lCXm/lvvHv3L3HpM+cPdcorMX0h4k6O3d8w6QvWrzMVsUlCZAACZBANBCA62+Jhx82Nc36Z4FZXr5yRWaGrZctUcKjyEZDczFWBSyTECiXgaR6tSrSv99n8nnfXvLTpKlGmXyxXh35b+FcmfTjOFN85qw5ZjlkcH/Zummt2ffPvL9MGpTJGzduyIZ1K9U1z/0wPGL4UAnZuUVKly5l8ji/Jk+ZbtqAMrl40XyZ8etUs3v9ho3y3+Ilzqwyfty3snf3VqlT222pWLp0ebj92Bg2ZKA0b+a2HrVs0dy0275d21vy2QQos2tXLZUtm9bYJBmsChXaaflKM5MGhRkSiIfJxC+B6y/mSvuTtzu2l6JFbioX/vLF1vQkSRKb+aTo3+EjR6PUTSgv9Wo/a5RJWOr8PSPmypFNBvXt6al7iHrzjRs11Kdr+2Q1hEDy5M4p3wzrZ+rH9j//Llbl6SJWjWAObL9eH8rYkUM8/d+0ZZvdfU8sH0yX1li2cTBQSmEkerNjN4GCDnmvSwd54vHiZr3sEyUN05cbvWg8HAd89n/y/cihMubrQTrlr5DJs2T5Sr9lTIYIvvYfOGT2wrV8QO+PtK1hxvobQZFYuyu2/i2kpTWKlwxGqIo/+rCsXrtBvh334y2lM2ZML/8sXKzBmfaEc1OAldUpmdT1CKM2GTOkNyM3mLuAGwy2nbJv/0GzuWNniHT/sLeO1F1xb4c9lDjzcp0ESIAESODOCJRTV9odISFyVC12/61cpa5jV9RyESoZdL4U9sUFSaIPTRDMYQ0kjRrWl5rPPGWyden2vlkuX7FSmjZvpS6F7vKwrkKyqsI344+ZsnnzVkkVNt8O6VBanYGOsA53Yl8C6y6kcuWKxs0OrnZQdmGZ3bFzlxQqVNBTrIg+SMbXQCqFCrqnyngP/iIjgtUkiO9uC236a9dWmky9oB7UcwmB4gzLbKZMmUw72bJnNeku1w2zRH8g/niYnfwyBN7p9D+ZpYMb+w8cCEcEVuu3dV9cF0z3giRLljRKh1K0cEF5qU4tTxn8Nnw9I+I3ZAMvITPyObc9FejKgYOHzWZ5dQmGO2y1yhVk2i9/mLRD6uZvBcp2tqyZzWbmTBkEz5O+fkM2f1xdtni5ocDw8/2EyeYYYREfNXaCZFajEKbZ4R4CiY97RVhwq1QpU+iz9xGZ+8+/Ok3vgoSqVwgE68jvq4zJEMFX4YIInhXfBINq26GLcUNu9FKdCErE7l2x8W8hldbbuGZaNG1olFb4ruMCtYKbQdcPPjUT95GG0ZY7lcsaMQ6CG5pVWGGdLfhQ/jutmuVJgARIgAS8CGB+mnWNWrxqlWdvXHALtp1F8CHI6jVrNer99YCKnC134cIFswqLhVVYSz/xuJRUZR1/gxo2bi6rVrstlLBY3o5gLiwEUVmtpEntjjRs99n0YC8j4hHsvsW29lOlSiW+3ITjqluwky9cc6EIQTJncnvHOfdHdj26nhGvXrtqmsSUMUhyhyKNQbb7UTA40PeT92XL1h3ymc43xj1sic7ltbFhvJlgnu9QjRQNwbM6ojPfqSRNmlQ9LN+XIcNHGeUZ82kR0RhW87gosfFvIZXW27iSMK+1RrVKMnvuAs+NDNXsUpdezEOAIjvqy4E6qhNfXmntHmH0DoIR2WZxg8R8V0REe79Lx8gWYz4SIAESIIHbJGBdo1Zt2GBqiCtuwfZwoWhCDmnU0yFDv5QO/2vnsTDAkvCABljyJbk1+BHkiVKPy5dDw8/13KzRYaGwwrKzZtUSU1+e/EXCqokXtnQvEGDQn9g2VqgVGw/xGJi1inDOHDn8FYswPV58d/uYQxudYvvqi0d0tnOv1GXdhEePGWsOKa67BeMgoMx8NdJ9PFBu4JJ73BGBO/TsOUmaIXIGikDPiNa6h3bxvlEbPRjbToGHABTpLdt0TnqlcrJNg/5YwTOjnVdr0+7lpfFiVK9FvNoGUrBAPnN/w/xfBMyC2Odvp+s0FEpI7VrPSMMXXzDRhZFm89qls4wpoF+ITuxPYNmG8rxt+06NajzAnIsD+iqwu/G6JH99upP02Pa3kErrbZ7NBjppHm4FdvQN1WDuAgRpmIvqvJGYHbfxVVknzSPwEiaMd+r6kUZpzKsPIkf0vWE5TGS726iSRUiABEiABAIQgGvUvkPu6RlxxS3YHlK5smWkqgaVmjf/Hxk4eKhG8h0jefLkNkosXG4n/PCdzRpu+dyzz5jAS7/8+rvgnaslij8mIXv2GPfcZi83MXnx/kLMY0UgJ28pX66McfP9+JPP5K/Zf8ubbd0RNp35nn/+OdMnzGF9VoM+nTl71uyGMlyxYnmjxDrzR2a9ZIniMubb72XiT5PllD6sPlWjugnEFJmyEeWJiEfndztFVPS+3Qc34cWLl5rjj8tuwfMXLpLlq9aEi4yMtzrA+mSDe+Ege/cfIokTJzKWtUAnPdAzIt4jagNuftJ3kJku1u2dt26p9smqFWX8T9NkwaIl7qjCGlkYgneToo77SRAzZsCQr01UZSj5CLBkAy/V1XfrQoqqizBeWbR67XqNytxfMLfVclq3YZN5JRdctp3iqwyijEMQtOmTPoPkkNf8ZlhvJ039VaMI5ww3MJgiRfiIxs524sJ6bPpbeNO3NS6Qi0V9xEj1S3XdwSHQrXj6L0N6DelfrrTp5U964SLUPuapQjCiHM+shf+yozk2NX688KckX97cYa+3iW9G1hYuWmoiElu/fFuOSxIgARIggegjgIfT5vXqmU/01Xr3avrm66HyVru2xjIKRRNKIuZv5sub128nChcuZIISQYHEPM4R+toaRAhOoPPrMuur2F5v3cqU7fH+R7Ih7DU27srcEVQb6/zYAjp1Be38PuNPuXjpssQLs4DYRh/Kn89YcdEG+oQIxQgY9cO4MYKIn/hb6i3WAuX999Lmq1qlkpkji+2Zs/6SEydP6pw073q8t23pm0vvv78R8bhZimtOAnAT/mvmb+bjTI8r6/Yag/EBr/LBMxyUwW7vtJeqlcqbw8BcUXjbQWDxxEBJEX0VDsSW1xWz7fwK9IyIvHg9CtqEpRCRaV033L8tZz3PPFXNWFiRFrJnnzGU4FU4nd563WTz+RsKe7b09M9ZYRxeT6kKIXghCBK8EqGwwtsR81wROwaCQEy5cmQ369t37DLnq1bNJ80AARj/NOUXT148q/srU0RfVWlfObR563ZjCce7YSHx9Xyn1ikPF3X6A5RXGJswAIFXXqbW30Rcltj0tzDelStXbv1FxGG6pzVgRhrHXJlgHEqovgMOPxy4aUTXDQLziY4cPa7zk67pKF+6KAcDCAYHtkkCJEACJBAxgbvxN+uEvoYDbriYhxqZv0lwuTuorsX6fKB/xzKFsxrgNTB4DzkCKPmr69Sp0+adq/72gwja2K8WIgSNyhRNfyvPqtU2efIHIj2HN+Izc3NvRDxu5uLa3SRwN343gY4HXgJwQYUyGhUJ9Ix4XZ/3MJ/avrbFX92Yv4poxmnTpNE54in8ZYs16TF1zqBo4n21uC9BiUVAU1+GHTyXI5CW3YdyUHYzpE+n1lbfAba8ywAmBiqSJ0/m9/ygDPpig2DFmhMQyzuyRgdC8+oUlcRhxj5f3aXS6osK00iABEiABEjgLhCIqQe5u9B1NkECQSPA303Q0N92wzxnt43uvigYGaU1vC/qfYGFB0kCJEACJEACJEACJEACJEACJBBXCFBpjStniv0kARIgARIgARIgARIgARIggfuQAJXW+/Ck85BJgARIgARIgARIgARIgARIIK4QoNIaV84U+0kCJEACJEACJEACJEACJEAC9yEBKq334UnnIZMACZAACZAACZAACZAACZBAXCFwzymtwX7dTVw58ewnCZAACZBA8Anwb1bwzwF7EPcI8HfDcxb3CLDHd0rgnlNa7xQIy5MACZAACZAACZAACZAACZAACcQeAlRaY8+5YE9IgARIgARIgARIgARIgARIgAS8CFBp9QLCTRIgARIgARIgARIgARIgARIggdhDgEpr7DkX7AkJkAAJkAAJkAAJkAAJkAAJkIAXASqtXkC4SQIkQAIkQAIkQAIkQAIkQAIkEHsIUGmNPeeCPSEBEiABEiABEiABEiABEiABEvAiQKXVCwg3SYAESIAESIAESIAESIAESIAEYg8BKq2x51ywJyRAAiRAAiRAAiRAAiRAAiRAAl4EqLR6AeEmCZAACZAACZAACZAACZAACZBA7CFApTX2nAv2hARIgARIgARIgARIgARIgARIwIsAlVYvINwkARIgARIgARIgARIgARIgARKIPQQSng4NjT29YU9IgARIgARIgARIgARIgARIgARIwEEgYYZ06RybXCUBEiABEiABEiABEiABEiABEiCBu0MgZO++gA3RPTggImYgARIgARIgARIgARIgARIgARIIFgEqrcEiz3ZJgARIgARIgARIgARIgARIgAQCEqDSGhARM5AACZAACZAACZAACZAACZAACQSLAJXWYJFnuyRAAiRAAiRAAiRAAiRAAiRAAgEJUGkNiIgZSIAESIAESIAESIAESIAESIAEgkWASmuwyLNdEiABEiABEiABEiABEiABEiCBgASotAZExAwkQAIkQAIkQAIkQAIkQAIkQALBIkClNVjk2S4JkAAJkAAJkAAJkAAJkAAJkEBAAlRaAyJiBhIgARIgARIgARIgARIgARIggWARoNIaLPJslwRIgARIgARIgARIgARIgARIICABKq0BETEDCZAACZAACZAACZAACZAACZBAsAgkjImGL1y6JDv27JXDx45J6PnzpomUDzwgmTNkkPy5ckrypEljolnWSQIkQAIkQAIkQAIkQAIkcJ8R2BWyV5YsXyXbtu+U4ydOmqNP/2A6KfBQPilTqoTkzZ3zPiNy7x1uPJdKdB7W7v37ZdXGTZItUybJkSWzpE6Z0lR/JjRU9h06LAeOHJESRYtInuzZo7NZ1kUCJEACJEACJEACJEACJHCfEZgw+WdZ+N/SCI+6YrnS0qR+nQjzcGfwCCxfs1byqmEzcaJEfjsRrZZWKKwrVWEt+9ijRml1tpoieXKTBqV1sXYMEhcU16vXXdJ3XohUyZdWKuRJ4zyku7Z+7YZLjoRekWypk0Rbm0fPXZGf1hyRJXvOSLWH0smrT2SNtrrjekU7T1yUiasPyyuPZ5Ecae6+V0BUz/fZS9fkuo49pU3m/4cenefkyvUbkih+fIkXz3et2J8wfjyJ7yfDdb2e9b8kSuCnAq320rUbkjRh1GYvRKZe3z2OODXQ8UZc2v/eQJwuK4MkUWTgv7Wbe2LqeG62ELW1QOca/U2cIGrXQtR6wNzRTeDy5cuSJEn0/b1y9u/q1auSMGFCvf/4vn9cv35dbugNJlEi/483gfoXaL+zP1gPlD/Qfu/6Am1Hd32B2uN+EojNBIaO+FY2bdlmulijaiUpWbyYZMua2WwfOHhYVq5eJ7PnLTBK7YmTp6R9m5ax+XDYtwgIRNuTAFyCYWH1pbA624cFFnmQF2Viu1y9cUM+mLlTFoWcDlpX3/9zp2T/ZKHsOH4h2vrQdcYOee/PHZIsUXw5fv5KtNV7NyqCUhmdLLz7vPvkRXPO952+7L0r4PbqA6GCAYE7kaie76rDV0qhvovvpMmAZeGPgUGOov0WS5KucyXnpwvlo1m75MLV656y2/X6rPTlCrM/zfvz5bVJ+ht37F++76w89c0qSdjlb3nww/nyxtQtskvPpZWDZy/Lq1om1XvzJFm3uVLn27Xyz85Tdrff5bnL16X5xI2S9oP5krjr31L961Wy59TNe8t3yw9Kwb7/hfug7ogkMsfrLP/nlhOm/vGrDjuTfa4H4vRfyBmpMGyFJFUGYNF1xnbBQEYgwbnxPs55O9z8ono8vtpCH14Ys1ZKDvI9mh1ov7NO9Kf337sl0/8tMOcaff97u9udy+abtv6o1Bq9xlxPT3yxTAb+s/cWDusOnTPnHsc9Y/NxW/S+Xs76a7aUq1BVvhj6lU8Ob7TrYPbv27ff5/7bTTysA9Kd3u4i+QoUlZx5CsorLVvLf4v9XCvXrkmzV16TGk/XilRzcAj7+dffpWKVGpI910NS4vFy8nn/QXLx4s37x3mdivTW/96WAoWLaZ788mKDJrJ//wFP/YH6h7oGfzFMipcsa/r/9LO1ZcKPkzzlvVfQpy+GfClFi5U0+dG3hf8uCpfth/ETDWvwQL1Tpk4Pt9+5sWXLVpMX5875OXs21GQL1H9nXVjv8d5H0qBRM+9kc0yo//Tp09Lk5Rbh2nK2W7tuA0/ZrVu3Ses27eSJspUkU9bcUrX6MzLim9Ge/VwhgWARgIUVCivcgLu//ZbUe6Gm5MqRTRImSGA+WEca9iEP8qKML8E9q9M7XX3t8plW96VG4X4/jZo0l59/+c1nXiZGDwH/Q5FRrB9zWKGQ4hNIbD6UKVawQKDs9/3+eo9kNMpl9miy+unfWpm67oi8VjqbDHwh7vHv/scOc01MavZIrLs2Kn+1Qvo895C8We723d+jer47V80t5y5fi1EWUCgHL9wrzUpmkfzpk8t/Oojz8exdkjxxfOmq7Z+6eNUoM6VypJYpzYuZ7fd0sOXkhWsyrUUx0zcM/pTIlkqt+tnkwJnL8n9/7RQMEMxsXdzsH/bvPkmg1pMhdQoKVLT+8/fI82PWyN73K0qaZP5vVfXGrpXNR86bcg8kTiBfLNwnUHJ2di8vKZIkMArsIe1/Xz0vVtI/ELFVOtDx2nqwRN6G49ZJqCrPZ9TqHZEE4rT2YKiUH7ZcahfNINNbPGrqbjdti8DjI6LfKqyVm5RBi1JZ5YkcqTxdyJ3O7SkQlePxFPZa+WT2bvlt0zFJqUx9SaD9zjJ95oXooNlO/a3kl8IZH5BfNh6TJ0eskhUdn5CS2VPJsr1n5cWx66RjxZyy6K1S8u/u0/LOb9vk/JXr8kGNPKaqZjpQ8cuGo1JIy287dsHwd7Zxv66fOXNWdu7aLb0/+1zqv1RXsmbJ4kGxYOG/Mm36L2b76rWrnvToWBkzZqzE1wfFXp/01N+vS74a/o0qpq1k1YrFkjrVzWsSbQ0cPFT+mj1HUqR4IFJNQ2H7ZuRoPZ56kid3Llm+YqUMGPiFJEuWVNq3e8PU0fLVtrJ9+w7TfvLkyWTkqG/l6WdfkGWLF8gDGlMjUP/mzV8gq9UL7H/t35S06dLK1Kk/GyX8ofz5pNTjJW/p55Bhw6V3n37y/ntddc5cfpk5c7a81KCp/DXzN3m02CMy8afJ8k7n7tK2zWvyScUKRqFt176THnMKeebpGrfUd/z4CXPeenTrLKlTp/bsT5IksVkP1H9PgbCVQ4cPS8iePd7JckotTbg+rqsHwwvP15KzZ8+aPKPGfCdQ/Du0b2e2U6ZyT+2aOWu2GYCoXKmiNGnUQNKlSycnTpwQu/+WBphAAneJAOawWpfg1q80kZyqoFp5o1N3szp80GdmiX3I89nAYaaMrzmuu3aHCDw5Iivbtm2XXOrOit/F5StXZMmSZdLmjfZyUn9jrVo2j2w1zBcVApjTGh0ya+G/rv2HD0e6KuRFmdgu569cc8k7s11vTdviaj99i6tAn0XmM+zfvZ6uvzJxg6vnXzs929uPnXdVHLbctWj3aZN2SZ84O/2y1ZX94wWm7OfzQlw1Rqx0/b7pmKfMiMX7zb6MH/3jajtls/l8OnuX2a+uqq4qX61wXdR68EHdSEOffPUnovbWHwp1NRq3zhwT2kJdH8zc4dp/+pKr/vfrTB9T9pjrKjNkmeuPzcc9/QOHrr9vdxXrv9i0+ebUzWbfNfXJxPEgHeWeH73GtefURU85Xyso+9Gsnab/lsmgBXtM1j5zd7uqDV/punBFHV7DZP6Ok6afC3edcrX4caNpB22h72AAua7+YAP/2ePpB/iu2HcmrAaXC23inA1ZuNcc2/T1R11axDVyyX5X+aHLzXE30OMHh9nbThg+g7VPYAJO4I90f7J87xmTF9cKjgl9G7PsgAvpWMcS9ePY0K49dziOvL3/NX23dUf1fHf5fZuHg21vjvb1xbFrffb9wJlLrtpj1ph9pQYvdQ2Yv8f0cW+A82b7hyWOAX1HPZBec3YZZkdCL5ttfE1Ydcikrdp/1pPmXAFb8MI15Eu+WrTP7F/ppzzK4JpAHaq8eKoIOXnRpOFcQ/C7LTFwiWf/7ax4H6+tA33HtQYO6MeX2ueIJBCnzr9tM/VcUbOllW4ztps0dQO3SbcsVSk3eZy/2VsyORL8HY8jS7hV/AZxfM+NWm3Oe7iduhFovzO/DrCYunBPtIL+4Hdgr6ev/9tv8uw+ccFmMftxb7SC+wzKbTx8zuTF74bicv00aYorY5ZcrsdKlHF17NTZg+TatWuuKtWeNunYv3PXLrPv+3HjXU8+9Zwr70NFzKd7jw9dqry4/p473/VCnfquNWvXeeo4dfq0SZs8ZZonzd/Kt9+NM/1Yu259uCyL/lti0ps2a2naC7czkhs39MSjv81bvGZKLFm6zNQ5c9ZfnhrUkmzSRo7+1pPmXPHXP5tn06bNprwqyzbJswQfMPzgo489aehTqTIVPX0C6zovNvTsx8pTNV9w1axVx6QtW77CVaHyk67Vq9330N9+/8PUqYMO4cr42wjU/xatXjf98S4/7MuvTTuqJIfbhb6if045deqU4dzqtbbOZK6TQKwgMH7SdFfbjt1cU3/545b+IB0fb0FepKOst+D32LjpKyZZB7DMvU4H+ly4/os8UsL8nv9ZsNBTDGkd3+7i2cY9APdd3E8h4yf8aPbrgJirXv3Grl6ffW7SsV3rhRfNbwu/Oe/7Ke4NuE/gHof7ZP8Bg134PUNsv7BU7wdTL9JPnznj6ty1h/nNow893vvIpd4j2OVauHCR67XX3zTH0LBxM9cff86KMN3sDMLXMr0XHj950nU2NNTvJ9rcgxEl2AZdiozSjLw2snBk8gc7z7BF+8z8z+ZqacJ8vbembzXWJPQLbo8bDrujJGP7wtUbslAtA9ZN9Kv/9sugBXulaOYUxgI3ee0Rmb3tpGf/Ci3fZspmFDVWqxMXrsrXi/fLVrUeQFSRkvnqJqn6qs4FdJm6G/+wXpbuPSO++hOovaxhc2NzpU0qT+RMLQXUcgYX4Uvab1hfP34mn1rIrkrHX7aa9vH18viNZm4v5tg1eiyzYL4dZMA/e6XL79ulTK7U8mGNvKZPsJBFJGsPnpOef+0yedEe3Ao7/bLNHOPDymjujpPmY+v4Ud1S16gFqkCGB+TB5G4LWYYUid19z5DcZBu8YJ+8/es2MwfwzXI5zLl6fPAy2a8WPQjaxDn7389bjTUPFsKv/tsnrSdvVkvcRWlaIoukTprQc1wo01H7pMqDtCufXVRxkh5hFl7s8xZMr7LWO1giwTWj9vG0Wt5wLZRSyx/OIeYl4xxuPXZeni+SwVhlH9L86Dusj5Conu/16iKJawFi24PV6ppeL7763nbKFmPZgkW3rn4wZxt9hLUusrJs3xlj2aqsc70hG/X6z67HhmO28lhW90i9vY5tOpawSs7cctwwSKC/J18Cqx6kWJYUvnabtC1H3b+7x7K520IirmtYA2F5hJw4f9UcG66jKeuOiiq1Jj0qX97Ha8vid4154cNfLGSTIlwG4lQ4k9vytDnsuFBZqTDLKa4Lf3JaLd0QXKfjVh7y3C/85fd3PL7y437UYNx6+UTvC+Vy37QA2byB9tt8drkv7DjscSEdv58y+ptZf/icyfZkgXRmCWsrmMF1GK7ksEBbyameJ36mNdos9/USFkC4t27avMVwgNsa1ju/2zEcl+07dkrx4o/Ke927yov16sjob8fKnL/nyWOPPiKqDMqvv87w5J+v1kikFSlS2JPmbwWWVEiRwjd/G6oEqZvpm9Ktyzs+rZf+6vJOX716rZw7d17KlS1jdu3QY4A8XLSoWeIre/ZsxpILa4gv8dU/Zz5YXiGlSj3uTDbrBw4eMsviOtXJCubYlixRXDarmy+kqAacXLduvehggc0ipUqWELjaQnbvDhH0LWTPXrN95oz7Hg5r+NRpP8v6DRtNur+vQP33Vy4q6Vu1f+D8fK1no1KMeUngrhBAlGAI5rBGVmxeW9ZfOXgg4F4H7wn8hlu1aG5+z70+6+eviFxRa+vBQ4f0PlTE5Nl/4KBMmPiTqKIoh/SekS5tWsG9C9u7du+W1q+1klBtBx4YM/6YacpcvXpNVKE194k32rSWfPnymqkQqsia/bZfT9d8QRb9t1iyZM5s0tu0fcvcN+CNgvs4PCdwH8f0gldatZaTeu99/71uUkLvUfDG8ZduKovFX/597mJxp4PRtY+eyiv/px8I3NFe+n6dPiCGypMaxCiQ/KkP5wjkZN0gXyqWycxRteXmhM3lWv12aUmeyO16l08fPiOSiPoTUXtQCj9XN0nMD3uucHpBPVZ+bXXzDzCUQ8wTxNxR1X1kurrhtS2b/ZaH80/n7JL6j2aSES+5H2KuqgI6WB/kB9cu4DcQD9qrlj+d/N22hGm6a7XcZl4blNUPnsxrFA7MZ0P/oNCOX3XIKNMZUySS/s8/JDg+DABg3QpcTUuo4rKswxMmqXHxTPLYwKXyzZL98vHT+UxaEVUI/nituFFqkNBswkbJ+2Ay2da1nDgVp11hSs2cNiWketj5Pa6Kz1B1X8UcTXuOTKVhX3BpxEP0cB2gAA/rHmzP7dC6BaVNmeye4EN/ve4+dhR/puCDku+zRTqQccK4dzrrtesRnW+bx7n013cER4IyCCbWzTJvumTSSAdBIisYsGj10yajoLZUd1QI3E+dCivSUoe59MI111swTxOK6/tP5vHeZbYxfxbzROESi0Eif3LorHv+MAYcnJIlVRLPIMBFHYyBAouBHiujGhSJdPAxX8eLejBY1VkHbH5u+egtx27b8V4G4tS0hPsP0Js63/edKjnNAMuYZQdNNRG5HttBJLhgW4GyP//NkrcE6PJ3PLacc6njK9J60mYzING1am7pNz/EuVsC7Q+XOWwDQeUgabwCh6XTe46d45xPf5ffNiwiLfU6e7i/e742rpVnCj0YVgsXgQhUr15VHlOl6tNefWTMqK912VfavdlGMnlN4fn4/z7wVKWD6zJ79lz5e+48dR19znzgTgwFGEqZjtBLgQIPhVNEPYUdK5h/+vfc+YK6ETQJgrrffrebcVd+S116vxo+wlEi8qt4MOzwdmdJn/5BadSovil45MhRs0wZ9rYCW1umjBnl0KEjdtOz9NU/z05d2R0SIj0/6S1P1XhSlfdbH4iPHXPPn07l5facNk0a2ROmhD5fq6aoBUVdhLuZh0j0ce68+UYJBIuXXqyrgwWPSX59KIVcvuz+Xbza2u3ujLRGDV+SLwb1x2o4CdT/cJnvYGPv3n2mdEblSCGB2EbAvtbGBl2KTP9sXls2UJkpk8ZLxQrlTTa4/UIZxPz3ZMmSmbRdu3abeaxwrZ80eZpJa9DgpXDVzvrjF3MvRiJiCkAWLfhb0uj94t23O0jBIo/Kl3o/fO7ZZ2TN2rVm/7ixY3RQrrRZv6Txf36f8adZt1+9e/WU5i83NQHnMPiFQbY+vT+Rli2amSzr1m8QuPZDgcbA04t1a0vjhu77JTKEhOzxmW7rj63L8E96d9BLvIcVr7VBlODICPKiTFwRBCyyYqP4wmIWSDAHC1ZVqyAgv/7tDyfq0mcslb6UoXAZHRv++hOZ9hzVhFuFYvarzi07ooGETql1BaJeup4HyWr53VY1WwgWFigeB9VCCEspBEFmYGE+ffGaTFKLMqzIVirlTSvNNSIvxBk5FlFiy+dOIzM2HTfKFJRjWJphvVqxL9S0YR/mbV3OJazC6EcVR/+g1EKstQ3riAQMKxwEcwvRzwaP5ginsJqdYV/JwgYQsGmjCGtcLkFwGyjSVmD1/ezZ/HbT5xJzOZ3HDEVqzvYTgsBNmVMmMWXA2p/4O9/+87sHP7Df2felaiGFlHVYzJw6Iay96rpt8tivfjo44IxMjLmI4Drr9eKeuaaYS2o9C2w5q0h5X9dQmqHc96ieRy3S4ee6oSzmubaevMlcE/+rkMNWJx3USo7r2wqs9GgXYtuy+9S93MwDx/bohoXlh6ZFTcRjWBihECJIVJ2HMxjvgts5XkRshqKPOaSw/qmXsG3aLP1xDMQJin9vvZZg1V/0nTv4m7U0Y5+/a69IphRy5tMqOuCTUA6FXjbW1m4abK3//L3Sq6Z70MZ20Nf581fvN0sOmAGrTZ3Lhrt+bV2B9uN37H0PsNbkS9dunkvUp1MfPPNl4TkArwjcN4vrYNS7v22XT+fsNuvwEKAEJgAls2vnt0Xd3URdw4wFoO3rr91iwVOXNlm5arWoC5kqguklUeJEcumSe6CpgY7a//rbDMEDUEFVVn9RZfSTnh9G2DgUnXfe7SpPqIXytVdbePKO+2GiUXr//WdOhJF9PQX8rGAeKR7Sfpo4zjNXNnnYcwcUWqdcvHjJzHt1pvnrn82DyLzuuacPSL/Pe9nkcMvkOpcWgrxOuagPl3aeLuaA1nqupvz40xTzQXqqlKmMso1zgw/my1qBgtpYlfCk+h57HN9gDfKEsnXr1JYqlSvabBKo/56M0bBiH8zxkH6vC+YAf95vULjD/OjDHpLGMb843E5uxDoCdh5rdHYMv0crWbO6n19xz7QCayw+EAyk9ejeRUo/Ed47A4OHVhBwDd4nUFghGNSrUL6c/LvoP7O9YMG/ZvlosYfNEl+4V3hLsUce9txHMcgGWbxkqbHgYv3YsWPmk1tjAKB9BJhCP9vo34Ci6injLx1lY7NEm9KaOUMG8x7WyARiAhC8sxVl7nWBcgKBq6Y/gfJnH7795YlsemTa81XXKlWeEBUULp5lVYFEQBgI9PJzYYpC+gcShysKd2IrViGDNRMfWL5gVUJ0Tyu50rpHpuy2c4lAO1B4IS+rC3Y/dTFesOu0zFGFv4C6AMOS6U/sMadJ6nYdRj5Y5/CQD+XFl5y/4u57BrXeRlWg8DqPyyqdka0H1to8vRaZh3RYnI+fP2mKRmIMJLJN+M13Nixgk7/rEcqf89hQEfjaU4dIvAP+2WOCGj1V4KbVCwM5C3adMteLvb8eO+ce+Mic6uZ1g7oRgRau0T2fvmnltx2GMoiIsbh+Jjd/JNyAAtyMMUBhBb+bLGF1oy1r6YV1Hm7hdnDJqXBjcOT1MtmMqziCN2VVi+ztHG/vv0PMYE51PX8IDGbPHVz/YUWpWSi9z3ojw6l7tdzSoWIOgRUZv0dY+GHRBUe4yTv7a689/P4SJXDfznFM71TOJb1UyYPrslP8nT9f1zQGIdpO3Wy8Eb5Xl2PIQv1NYoAIxwylP6L9eI2Wr3uAHVw6GnrzXKLuw2qBtQMsXy8+IHnUA8B6SYBnzZGrDQcqraAVOalWtbKULFlcZs+Za6ysGTPe+jcXlj1YUKFkJUyogcvUUmiti1WqVDJKGEbsESgI8sILz/ltPDT0nDRt3sooZ6O++UoSaGAmCMrqfCsTtGTS5KkmbcnS5Wakv1fvvtKkSUPJkzu3SY/oC0rc8K9HygfvdwunyGXK5B7IQIAgPDhC4NIHV73MmTN5qvTXP5sBv90u3d6TlStXy8/TJklmL6u0zZch7NnFMrHpeFDMmjWr2cTD7uiRw02UXlg68MD7srLRuWc2e7ilVbyRWFADVLZ/6w0TNGvt2nWeYw3Uf2eFqA884G7ofP3PkaNuq3RkXkmUPXs2U6W1Hjvrv9fWr6il27rS22ODhUujYtlNLmMZAUQDPnLsuOC1NogSHBlBXgjKRodgsKlf395GsUwUwftFbVvnL1yQbNnc9wibliZNanMvhDJ8JiwwGgKlRVYuhg0yQrm1faiq9/6cOXKYKn6e+qOJJj9y1Bj5adJU09/mzZqIv/TIthuMfNGmtObXCFp//rNA8B7WQIor8uBTs3KlYBxzjLSJh21fgnmOeJiGm2jvsAyYm+oUzO0au+KQsU5CebMPwM48kV2PTHu+6oJLL2Rrt3LG/RVzyDAvEgoI3F4hC3efkqoOa2amlG5lJEeaJPJ5rZuuuiazfuGB0z502jRfS1ipoPDYOZCwLOEDF+FZW08Yt2Tvck6lK3NYPxbvcVumkBdKCx668z3o2/Jvy0ApxlzcqAgemiN6cMaDT0QC11f0bXH7UsbCDqUwefe5hnVE5aJjX9GwOZPgbV0tnRZeuEtbF2vv9nANw12zU6Wc0qVqrnC7MagAqxvmJFrLIObwQuw25jLW0GsKiuOPzR6+xe0X7+OE2z3yrepUWhVStwXaNmTd6+02ltaSPn/nSXUZd3tuWMse3MV9CbwAILBe3+7xwp0cgzPer8JCf/DKmnblc/jkGBlO6Bus03CRxaWEOaoY3EBaoGsPZSEYUIJy6Yz0G9H581UvrMU4Rgg8MCB2Piq2S+dKFeH+WkXS+7wHYFAB98TZ6mnQpqz7QQO/Abyyxr4vGtGpMzgGyeCNUVrnvOKagoLtHIgwHeOXXwKD+vfV9xSukafV1dVbMK8KCiuUwLfebGt2P1/7Jc/IPh6Amr3cxMyVgkts9WpV/CpyV69eFSjABw8elDl/zVA35JsWcUQqhlsxZOZf7rmuyGe3a9SoHlBpxVzPDp3eVUvBq56+mgr0C5YDiAZ5Mgof1teuXY+FwCIBiah/JoN+DRw0xFg3vx09QsqWecIm37LEsUE51qAsgoc/CBQcDA40adwwXH5YVPBBBGS4TCM6cGTERvW11s7I9N9Zbx61sEBZXq5z4cqVK2N24W/Tb7/9YfoOy28gQVRk5Bs1+lu9Dhp7HogDlYuL+xEFFm6clLhDoMBD+YzSivewQmm1kYIjOgLkhaBsdEj8+AkkceKbA/OB6sR0ANwHnINJizXqcL68eSR+/PhqhXXfy1asXCUYdIQgb0SSLcwCXKF8WXO/9s6LewjiCOAer0GlZNDgoea+5S/du3xs2o42pTW5jiqWUN/pxRoyPqJ3tUJZRZ6Smhdl7gXBPFG4wuJhFZagUUsPhDus9uriiLlmeA1HhTxpbtn/yuNZjdKKdw22KJVFft5wzFhx8HB/OxKoPV91wjoD2XH8orpRxpMRqoBYKZk9pbH4fLlov3E/rJQ3jenfi8UySpPimWXC6sNG+XpW56DC4oUgMvbh09bhvcRDKdwUn9KAK9+pwo4HbLhaWmmt1rD2GjgJ0uixmyPl2IZ7ISw+CB6EviIIFNobrXP/EFQIjPvN24Os0sCrrEnUL1hi8foWKASYX1n34YwCyx1cEW9X0uqcPCgJePiGcuI9z9LWa61jCCIEy9t3y91WLLs/JpdQ0moo88/mhsgODWyTXBU3DJgEEihjUDhh+cP87N/VldsKgvM00Hm8CCYGt1u8sgYuquBaU+cgwmIG6/IzaimDst5XX3Myd7tboUUdBTMmFwSjgtsuXOkxd3HL0Qvmg/0YiME59iVQqirq+YblL7e2A2XmDbUO4jzU0+sTCk7fuXv0fKQ0r+pZoXPFh6jlEgwist4HOl643DrdbjHwgvfPYu6xnc/sq7+BOME1evLao1I5XxpJnCC+vr5nr7Gs/v7qY76q86Th/bAIplZCrzv0xc6D7Rw2uBDoeDCf1FtwbW5Ut2Cn4N2qffTasel1it5UTJDPe7+zrF3Hbw8BwvCeXxxfRZ02oBGszW64fEPK6vnGdYmgcjhXCMaEwGmw0FNhNYgi/QWrHT6+BHMwIRpp1yhVeGXDps2bjVXQ5kdQD1g3x+2ZICOGD7XJtyy7dHvfKHGdOraXHdt3mg8y4RUpsPYunD87XBm843TIsK886RqlWLp2/0C+/uqLWxTYbdu2S/2GL5v5sOVVAZs9+29PXaVKlTQKcZnST0ivz/pKjhzZVUlMLV26vmcULswTgwTqH96hine/1niymiRSlz1nG1CqnQKXPgRmQX5YL0pr22AEeblJI7OEkg0LJV6Xc+r0Gfnwo49NemN9PQYEr+3BHN+hXwwwlm0ozJmzZDYKON4vizluUBgbhc1DC9R/U6njC8GT+g0YLF17fCBvtHnNWIAxxxbW5w7/a+fI6X8V1loE6Or+3ofybK26GjimpbFco39QiF9v3cp/Ye4hgRgmgNfW4JU3s+ctkMc1GJPzlTe+mt6774DJi30oGwypp3NLobTCowP3Co14bu4T3bu+a7oDRRUDYpjW8WrLV2THzl3mvmo9SHz1GQNzeLUZ7kF4pRYCwu3ara/v0ekShQoV1Hmy68wyuSqv12/o1Cmd3oB7vq90X/XHprRoU1pxUHmyZzfHtkSVUlhbc+gN2EYUxhxWuARDaYXCavPGJhi++qIzT3wlh0uDgoXgQHi/IsRYoTbezNKjem7zAKqvuNEow+d0f26jxNoAM7Be4l2Wo5celEW7z0grVcDg2mddbhE8x0pk+hOoPUd1tlp5tXRWE6Dn0QFLTNorj2cxS1h6EDH411aPycsTNpgot9gBl906quhhvuMxfVhGpF18IAigFEhphUI3Rd8Vi4dcyFtqmYISaaW+BquC0goLk3UZtPugFGAuaKUvVxgFat4bJc2cUrgXYh6flUG1CxiFxm57LxHICRbyz1XBxQfWH1jz9Jn6tgTnE5GXP9QBirJDl5vAXRVVwfcWPIRDmYPVEgLFH2INtFE93878gfqOvBNffsRcX3j3JRS9N5Qn5pjiHan+RF9bY3bBgl3727XhslmLMd6nWfc7HbTSY4dAmfyuUVGzjsEMKE4Qe9xmQ79gpe9cJZexqiMNcxedAlYIoOVPfmz2iHmnJ9yKITiPc9uWNJZJWPAwQILBDCvwbPiidkG76XMZmeP1WTBAIjwpIuKk+qaZQwqFHwLle1zjouY3FVHVCNKEqN02WjbyItqvHfiKqeOJqE8R7eumLtB7T13y3DOQd4wGXrKDE/30msDvCVHG8Z5acMD9xgbDc9Ztr1r1kKY4CETmb0VajWb5jgYCwTtPvxv7g5n7lDdPHuPibqt65OGiRimE4viUl/Jm82A5f/4Cs4lRfKdUr1ZFJvzwnTPJ5/qaNetkjT47JEp46wAK5tRCoHA1b9E6XPk/fptulOIRXw81VgS44ELwkDd18kRPwJRA/YOVFgJrKT5OOXIwxLlp1vE+V0QHff/Djz37Bg/qZ/qChMvqsoeHyHd39TD7YcmDBdq6aCMCMZge0uciuGPv2bvXKKpQBiHo//Avv5BUYe9LDdR/U8jxhYGKEV8PM/OLMZ/NyivNm0rHSCqtKIP3TaZOncoE8mrf4R1bjeDhm0ICwSSQN3dOqViutFFcR46dYN7D6k9xhcKKPBCUQVlfAmsnJH4899JXHmeaze9Ms+vOZzObVqf287JlyzYZ+uVwE1kY6XAxhgcJBPeHHyd8LyO+GW0GtjDoBUUTc2EhvvoFV39Mx3jjrQ7S9s3/mXwY8IJlFQNhn/XpZ97NjB3weOnfr4+ZpuAr3RSOxV/x1F1EH5OiVy6om8wOHWE8fOyY57U2CLqEOaxwI75XLKxOanD5DdFXp+TWyX9W2XTud67DCvKqWqTmq7JlXxni3I+5e4XU6grXWmcAJ2eeqKwHas9ZF9z/4PYLK48vgeUK4m3tQPpRVUzg0miVcV/lkVZh2ApJoQ+hUBBh3YSbpnewHrgmZv9koXlgxxxXb8FVC+ud91xgWLqPaUCpPOmS+j0G77qg2OCVId7uqN75IrttX00EZT8igdURwZ7wQB5MQZRoWJwv9almBijupC84L/gdpNJBCft6ojupLyplwRPn0gbbcpaFS+pOtSynU6URgbOCLYE4wYUZ1zKs1BGMJdxyGMeUAV57BJf+QNffLYWDkIDAWpj3iuP0dd9AsDtEFMbgiq/9QejyPdkkIl9euHBRMmRIf8vxYZ5VhUrVjTVx0IC+t+yProR3u/QwVl4ooXcimGcKV93s2bPdSTWRLntB56jB9Rfzx2CB9RYE+Emo8819scVrJ6xSinJ4HIMVM77OBc6sLsh2TrB3nVHZNnN7VUHGOc6ZM4c8cAcBMFFH6LlzM98X6wAABIhJREFUklGf5SJ6WI9K/5iXBO6UwNAR38omVQQhNapWMq/AsVGCMYcVLsGwxkKKFNL54m1amvVgfiG4GQa98MqaiFz1cf995LFSRtmcPuXHCLuM+wfmrGN+Nn7rTsFc+vPndT5tmCux3ecv3e6/m8vlOmiZV3XExBHMDY4RpfVuHmRcaAtzGKEMIqLtpiPnzCthEqtCs+HdskZhQxCk33SOWLGsKST00nUzNxBz5RCx00bajMpxBmovKnXFRF6n0updP5RYWOTg3osIort6lL9FMfUuw+2oEYB1G+6gCIz1j84RhBUSVu7v1aJHIQESIAEQwMMSogrD6ghXXlgJYXWNKanxdC0zzwpzaCkkQAIkEBUCEyb/bCyuEZWBhbVJ/ToRZQn6PgwMwa0fr6rBABPe3wq3fnhxOF9ZE/SOxkAHIqO03josGAMdud+rhFUR7yBFBFAI3B0HqXuifY0J5hVifiPmb8FahMA1eJ3I7SisqD9Qe8gTTMmqc+UQWMWXIKIr3H4x93J804epsPqCdIdpsKJjviAiy8LKC/fgQK/sucMmWZwESCCOEcDrYxo1aW563fOj92NUYUUj348dJQ/q/FcKCZAACUSVAJRRzFNdsnyVbNM59fY9rIgSjKBL2OfPJTiqbcVkfngwwHsDc9x37tpt5qriNWMN678Yk83Gmbppab2LpwoBUuDq58vP3XYDbozR5QYXmfZsu7FpGZ0MYtNxxba+kHNsOyPsDwnELgJwN4PFNTrcVGPXkbE3JEACJBC7CcC139eUg9jd69vvHS2tt88uRkriNRmBJLoUVrQTmfYC9ScY+6OTQTD6H1faJOe4cqbYTxIIDgG8948Ka3DYs1USIIH7m8D9pLBG9kz79tGMbGnmIwESIAESIAESIAESIAESIAESIIEYJEClNQbhsmoSIAESIAESIAESIAESIAESIIE7I0Cl9c74sTQJkAAJkAAJkAAJkAAJkAAJkEAMEqDSGoNwWTUJkAAJkAAJkAAJkAAJkAAJkMCdEaDSemf8WJoESIAESIAESIAESIAESIAESCAGCVBpjUG4rJoESIAESIAESIAESIAESIAESODOCFBpvTN+LE0CJEACJEACJEACJEACJEACJBCDBKi0xiBcVk0CJEACJEACJEACJEACJEACJHBnBKi03hk/liYBEiABEiABEiABEiABEiABEohBAgmPnTwZg9WzahIgARIgARIgARIgARIgARIgARK4lUDyZMluTfSRkjBDunQ+kplEAiRAAiRAAiRAAiRAAiRAAiRAAsEnQPfg4J8D9oAESIAESIAESIAESIAESIAESMAPASqtfsAwmQRIgARIgARIgARIgARIgARIIPgEqLQG/xywByRAAiRAAiRAAiRAAiRAAiRAAn4IUGn1A4bJJEACJEACJEACJEACJEACJEACwSdApTX454A9IAESIAESIAESIAESIAESIAES8EOASqsfMEwmARIgARIgARIgARIgARIgARIIPgEqrcE/B+wBCZAACZAACZAACZAACZAACZCAHwL/D6jJF8E9xFi3AAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "id": "8a69dd26",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9076b05a",
   "metadata": {},
   "source": [
    "### Creating an Estimator and start a training job with `run_ner.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27bb69d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={\n",
    "    'dataset_name': 'NER_ENGLISH_PERSON',\n",
    "    'model_name_or_path': \"xlm-roberta-base\",\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 5e-05,\n",
    "    'embeddings_storage_mode': 'gpu',\n",
    "    'num_epochs': 2,\n",
    "    'context_size': 64,\n",
    "    'output_dir': 'ner-english-test',\n",
    "}\n",
    "\n",
    "# configuration for running training on smdistributed Data Parallel\n",
    "# distribution = {'smdistributed':{'dataparallel':{ 'enabled': True }}}\n",
    "\n",
    "# instance configurations\n",
    "instance_type='ml.p3.8xlarge'\n",
    "# instance_type='ml.g4dn.12xlarge'\n",
    "instance_count=1\n",
    "volume_size=100\n",
    "\n",
    "# metric definition to extract the results\n",
    "metric_definitions=[\n",
    "    {'Name': 'epoch', 'Regex': \"epoch.*=\\D*(.*?)$\"},\n",
    "    {'Name': 'loss', 'Regex': \"loss.*=\\D*(.*?)$\"},\n",
    "    {'Name': 'f1', 'Regex': \"f1.*=\\D*(.*?)$\"},\n",
    "    {'Name': 'precision', 'Regex': \"precision.*=\\D*(.*?)$\"},\n",
    "    {'Name': 'recall', 'Regex': \"recall.*=\\D*(.*?)$\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1440a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator\n",
    "huggingface_estimator = HuggingFace(entry_point='run_ner.py',\n",
    "                                    source_dir='.',\n",
    "                                    metric_definitions=metric_definitions,\n",
    "                                    instance_type=instance_type,\n",
    "                                    instance_count=instance_count,\n",
    "                                    volume_size=volume_size,\n",
    "                                    role=role,\n",
    "                                    transformers_version='4.17.0',\n",
    "                                    pytorch_version='1.10.2',\n",
    "                                    py_version='py38',\n",
    "#                                     distribution= distribution,\n",
    "                                    hyperparameters = hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4fbbce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting the train job\n",
    "huggingface_estimator.fit(wait=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_machinelearnear-lightninglite-sagemaker-flair",
   "language": "python",
   "name": "conda_machinelearnear-lightninglite-sagemaker-flair"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
